{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce33339-230d-4e79-be55-021a74a8f98c",
   "metadata": {},
   "source": [
    "# 基于FunASR进行推理 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc5879-48db-44ea-9891-453e9e80ae36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 可执行命令行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cac19-c69d-4a27-86cb-134f127aae2b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "funasr +model=paraformer-zh +vad_model=\"fsmn-vad\" +punc_model=\"ct-punc\" +input=vad_example.wav\n",
    "# 注：支持单条音频文件识别，也支持文件列表，列表为kaldi风格wav.scp：wav_id   wav_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e88f0-fa4c-408c-a875-dd9a4cb5fbc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 实时语音识别 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5ea56c-5a57-4d91-be73-7f4ce7659c0e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-30T15:27:16.198490Z",
     "iopub.status.busy": "2025-01-30T15:27:16.198189Z",
     "iopub.status.idle": "2025-01-30T15:27:34.735341Z",
     "shell.execute_reply": "2025-01-30T15:27:34.734804Z",
     "shell.execute_reply.started": "2025-01-30T15:27:16.198470Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.3.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.624: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.55it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'text': '欢迎大家来体验达摩院推出的语音识'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.829: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.22it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_1t9EwL56nGisi', 'text': '别模式欢迎大家来体验达摩院推出的语音识别模型'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "chunk_size = [0, 10, 5] # [0, 10, 5] 600ms, [0, 8, 4] 480ms\n",
    "encoder_chunk_look_back = 4 # number of chunks to lookback for encoder self-attention\n",
    "decoder_chunk_look_back = 1 # number of encoder chunks to lookback for decoder cross-attention\n",
    "\n",
    "model = AutoModel(model=\"paraformer-zh-streaming\", model_revision=\"v2.0.4\")\n",
    "\n",
    "import soundfile\n",
    "import os\n",
    "\n",
    "# wav_file = os.path.join(model.model_path, \"./asr_example.wav\") \n",
    "wav_file =\"/data/coding/paraformer_Streaming/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/example/asr_example.wav\"\n",
    "speech, sample_rate = soundfile.read(wav_file)\n",
    "#chunk_stride = chunk_size[1] * 960  # 600ms  # 每步处理的样本数：16个样本点每毫秒，600ms 对应于 10 * 96 样本\n",
    "chunk_stride = chunk_size[1] * 8000  # 5s \n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size, encoder_chunk_look_back=encoder_chunk_look_back, decoder_chunk_look_back=decoder_chunk_look_back)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0994d5-b54d-49d5-889e-2ae95065842a",
   "metadata": {},
   "source": [
    "注：chunk_size为流式延时配置，[0,10,5]表示上屏实时出字粒度为10*60=600ms，未来信息为5*60=300ms。\n",
    "每次推理输入为600ms（采样点数为16000*0.6=960），\n",
    "输出为对应文字，最后一个语音片段输入需要设置is_final=True来强制输出最后一个字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705490b-780c-4459-8550-a96fd36bb35c",
   "metadata": {},
   "source": [
    "## 语音端点检测（实时） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436785f2-d290-47c0-a3c2-2932689ff83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T15:27:34.736452Z",
     "iopub.status.busy": "2025-01-30T15:27:34.736102Z",
     "iopub.status.idle": "2025-01-30T15:27:38.799303Z",
     "shell.execute_reply": "2025-01-30T15:27:38.798799Z",
     "shell.execute_reply.started": "2025-01-30T15:27:34.736434Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "chunk_size = 200 # ms \n",
    "model = AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\")\n",
    "\n",
    "import soundfile\n",
    "\n",
    "#wav_file = f\"{model.model_path}/example/vad_example.wav\"\n",
    "wav_file = f\"/data/coding/data_download/wav_mp3_datas/VAD_30s_mono.wav\"  #单通道音频\n",
    "speech, sample_rate = soundfile.read(wav_file)\n",
    "chunk_stride = int(chunk_size * sample_rate / 1000)  \n",
    "print(chunk_stride,sample_rate) # 9600\n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)  # 计算总块数\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size)\n",
    "    if len(res[0][\"value\"]):\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139cd7c",
   "metadata": {},
   "source": [
    "语音端点检测 output 解读：\n",
    "    [{'key': 'rand_key_wbFOdbpcao8Pu', 'value': [[78530, -1]]}]\n",
    "    检测到一个语音片段，起始位置为 78530 采样点，结束位置未确定（-1）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f366d-c87f-4456-b198-9df396591ffa",
   "metadata": {},
   "source": [
    "## 时间戳预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a272affa-d568-4b5d-b7e7-63b626f31ada",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-01-30T15:29:13.523220Z",
     "iopub.status.busy": "2025-01-30T15:29:13.522900Z",
     "iopub.status.idle": "2025-01-30T15:29:18.504922Z",
     "shell.execute_reply": "2025-01-30T15:29:18.504319Z",
     "shell.execute_reply.started": "2025-01-30T15:29:13.523199Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.2.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "New version is available: 1.2.3.\n",
      "Please use the command \"pip install -U funasr\" to upgrade.\n",
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/iic/speech_timestamp_prediction-v1-16k-offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 23:29:15,278 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.019: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:02<00:00,  2.23s/it]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'text': '欢 迎 大 家 来 到 魔 搭 社 区 进 行 体 验', 'timestamp': [[34670, 34910], [40590, 40830], [44430, 44670], [46890, 47130], [61010, 61250], [65210, 65450], [69390, 69630], [72270, 72510], [76350, 76590], [83390, 83630], [89670, 89910], [92670, 92910], [96390, 96630], [99790, 100030]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "model = AutoModel(model=\"fa-zh\", model_revision=\"v2.0.4\")\n",
    "# wav_file =f\"music_piano_man.wav\"\n",
    "wav_file = f\"{model.model_path}/example/asr_example.wav\"\n",
    "text_file = f\"{model.model_path}/example/text.txt\"\n",
    "res = model.generate(input=(wav_file, text_file), data_type=(\"sound\", \"text\"))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23408c47-c2b7-4da8-9134-9514b4d43cad",
   "metadata": {},
   "source": [
    "// 终端查看模型记录\n",
    "root@dsw-829530-77c6b896d4-6ct46:/mnt/workspace# cd .cache/modelscope/hub/iic\n",
    "root@dsw-829530-77c6b896d4-6ct46:/mnt/workspace/.cache/modelscope/hub/iic# ls\n",
    "speech_fsmn_vad_zh-cn-16k-common-pytorch    speech_timestamp_prediction-v1-16k-offline\n",
    "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a80ae-c0ae-40f9-af71-25b28f28dba8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "更多详细用法（[示例](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)）\n",
    "\n",
    "\n",
    "## 微调\n",
    "\n",
    "详细用法（[示例](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)）\n",
    "\n",
    "\n",
    "## 相关论文\n",
    "https://arxiv.org/abs/2206.08317\n",
    "\n",
    "title -- Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition(2022)\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
